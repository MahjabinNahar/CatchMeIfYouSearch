# Catch Me If You Search: When Contextual Web Search Results Affect the Detection of Hallucinations

This repository contains the data used to <em><strong>investigate human detection of varying degrees of LLM hallucination with and without contextual web search results</em></strong>.

The work is to support the [arXiv](https://arxiv.org/) paper ["Catch Me If You Search: When Contextual Web Search Results Affect the Detection of Hallucinations"]() by Mahjabin Nahar, Eun-Ju Lee, Jin Won Park, Dongwon Lee.

## Citation
If you find this repo helpful to your research, please cite the paper:
```
@inproceedings{nahar2025catch,
title={Catch Me If You Search: When Contextual Web Search Results Affect the Detection of Hallucinations},
author={Mahjabin Nahar and Eun-Ju Lee and Jin Won Park and Dongwon Lee},
booktitle={First Conference on Language Modeling},
year={2025},
url={}
}
```

# Download the dataset

You can check and download the [data]() used in this study. 

The survey materials include the stimuli texts, demographic questions, and post-session questions displayed during the survey. The survey was conducted in Qualtrics. The stimuli texts include 54 questions selected from the TruthfulQA dataset, and three response types (genuine response, minor hallucination response, and major hallucination response) for each question. The responses have been generated using GPT-4, Llama-3.1, and Gemini 1.5 Pro during August 12-13, 2024.
